
@article{fan_hierarchical_2017,
  title = {A Hierarchical Multiplier-Free Architecture for {{HEVC}} Transform},
  author = {Fan, Chunxiao and Li, Fu and Shi, Guangming and Niu, Yi and Qi, Fei and Xie, Xuemei and Jiao, Dandan},
  year = {2017},
  month = jan,
  volume = {76},
  pages = {997--1015},
  issn = {1380-7501, 1573-7721},
  doi = {10.1007/s11042-015-3114-3},
  abstract = {In spite of high decorrelation performance, the large block size of transform coding in High Efficiency Video Coding (HEVC) brings about undesirable complexity in hardware design. The heaviest burden in HEVC transform implementation is the large quantity of multiplications. In this paper, we propose a novel hierarchical multiplier-free architecture for HEVC transform, which can achieve a multiplier-free partial butterfly combined with matrix multiplications (PBMM) architecture based on vector decomposition (VD-PBMM). In the proposed architecture, the complicate matrix multiplication in PBMM is achieved by several simple stages to simplify its VLSI realization. Each stage only involves additions and multiplications with power of two which can be achieved by shifters and adders. In addition, the new architecture can balance the distribution of adders to improve the system frequency. The proposed architecture has been evaluated with TSMC 0.13um CMOS technology. The relative system can run at 400 MHz with 92 K logic gates, which is about half of the PBMM method when the latency is 8. The proposed architecture can achieve the transform without any performance loss compared with the standard, and it is suitable for the hardware implementation in VLSI design.},
  journal = {Multimedia Tools and Applications},
  language = {en},
  number = {1}
}

@article{fan_improved_2016,
  title = {An {{Improved Signed Digit Representation Approach}} for {{Constant Vector Multiplication}}},
  author = {Fan, C. and Niu, Y. and Shi, G. and Li, F. and Qi, F. and Xie, X. and Jiao, D.},
  year = {2016},
  month = oct,
  volume = {63},
  pages = {999--1003},
  issn = {1549-7747},
  doi = {10.1109/TCSII.2016.2539079},
  abstract = {In this brief, the multiplier-free implementation of the constant vector multiplication is reexamined. A novel improved signed digit representation technique is proposed to overcome the two main drawbacks of the current multiplier-free techniques: 1) computational redundancy and 2) circuit irregularity. The fundamental difference between the proposed technique and the existing multiplier-free techniques is a novel optimization framework based on vector decomposition. The constant vector is decomposed into two terms: a ``public'' vector and a ``private'' matrix which consist of the public operations shared by all of the entries and the private operations of each individual entry, respectively. In this way, the overall data flow can be divided into two regular steps: multiplied by the ``public'' vector first and then by the ``private'' matrix. The computational complexity reduction task is then achieved by minimizing the length of the ``public'' vector and the number of operations in the ``private'' matrix. Experimental results demonstrate that the proposed technique outperforms the existing multiplier-free techniques in fewer operations and more regular circuit structure.},
  journal = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  keywords = {NSFC,saliency},
  number = {10}
}

@inproceedings{han_enhancing_2011,
  title = {Enhancing {{Gradient Sparsity}} for {{Parametrized Motion Estimation}}},
  booktitle = {Proc. {{British Machine Vision Conf}}.},
  author = {Han, Junyu and Qi, Fei and Shi, Guangming},
  year = {2011},
  pages = {42.1--42.0},
  publisher = {{BMVA Press}},
  address = {{Dundee, UK}},
  doi = {10.5244/C.25.42},
  isbn = {1-901725-43-X},
  keywords = {publication},
  lccn = {0000}
}

@inproceedings{han_gradient_2011,
  title = {Gradient Sparsity for Piecewise Continuous Optical Flow Estimation},
  booktitle = {{{IEEE Int}}'l {{Conf}}. {{Image Processing}} ({{ICIP}})},
  author = {Han, Junyu and Qi, Fei and Shi, Guangming},
  year = {2011},
  month = sep,
  pages = {2341--2344},
  publisher = {{IEEE}},
  address = {{Brussels, Belgium}},
  doi = {10.1109/ICIP.2011.6116110},
  isbn = {978-1-4577-1304-0},
  keywords = {publication},
  lccn = {0000}
}

@article{li_bandwidth_2011,
  title = {Bandwidth Adaption for Kernel Particle Filter},
  author = {Li, Fu and Shi, Guangming and Qi, Fei and Zhang, Li},
  year = {2011},
  month = apr,
  volume = {22},
  pages = {340--346},
  doi = {10.3969/j.issn.1004-4132.2011.02.023},
  journal = {Journal of Systems Engineering and Electronics},
  keywords = {publication},
  number = {2}
}

@article{li_multiscale_2019,
  title = {A {{Multiscale Dilated Dense Convolutional Network}} for {{Saliency Prediction}} with {{Instance}}-{{Level Attention Competition}}},
  author = {Li, Hao and Qi, Fei and Shi, Guangming and Lin, Chunhuan},
  year = {2019},
  month = oct,
  volume = {64},
  pages = {102611},
  issn = {1047-3203},
  doi = {10.1016/j.jvcir.2019.102611},
  abstract = {Data-driven saliency estimation attracts increasing interests in recent years because of the establishment of large-scale annotated datasets and the evolution of deep convolutional neural networks (CNN). Although CNN-based models perform much better than traditional ones in saliency prediction, there is still a gap between computational models and human behavior. One reason is that existing approaches fail assigning correct saliency to different objects in scenes with multiple objects. In this paper, we propose a multiscale dilated dense convolutional network to handle instance-level attention competition for better saliency prediction. In the proposed architecture, dense connections encode inter- and intra-class features for instance-level attention competition, dilated convolution collects contextual information to enrich feature representations of instances, and shortcut connections provide multiscale features for attention competition across scales. According to evaluations on three challenging datasets, CAT2000, SALICON, and MIT1003, the proposed model achieves the state-of-the-art performance.},
  copyright = {All rights reserved},
  journal = {Journal of Visual Communication and Image Representation},
  keywords = {NSFC,saliency}
}

@article{li_optimization-based_2009,
  title = {Optimization-Based Particle Filter for State and Parameter Estimation},
  author = {Li, Fu and Qi, Fei and Shi, Guangming and Zhang, Li},
  year = {2009},
  month = jun,
  volume = {20},
  pages = {479--484},
  journal = {Journal of Systems Engineering and Electronics},
  keywords = {filter,particle,publication},
  number = {3}
}

@article{lin_high-resolution_2012,
  title = {High-Resolution Ranging Method Based on Low-Rate Parallel Random Sampling},
  author = {Lin, Jie and Shi, Guangming and Chen, Xuyang and Qi, Fei and Zhang, Li and Xie, Xuemei},
  year = {2012},
  month = mar,
  volume = {22},
  pages = {219--225},
  issn = {1051-2004},
  doi = {10.1016/j.dsp.2011.11.006},
  copyright = {All rights reserved},
  journal = {Digital Signal Processing},
  keywords = {publication},
  number = {2}
}

@article{qi_camera_2007,
  title = {Camera Calibration with One-Dimensional Objects Moving under Gravity},
  author = {Qi, Fei and Li, Qihe and Luo, Yupin and Hu, Dongcheng},
  year = {2007},
  month = jan,
  volume = {40},
  pages = {343--345},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2006.06.029},
  copyright = {All rights reserved},
  journal = {Pattern Recognition},
  keywords = {publication},
  number = {1}
}

@article{qi_constraints_2007,
  title = {Constraints on General Motions for Camera Calibration with One-Dimensional Objects},
  author = {Qi, Fei and Li, Qihe and Luo, Yupin and Hu, Dongcheng},
  year = {2007},
  month = jun,
  volume = {40},
  pages = {1785--1792},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2006.11.001},
  copyright = {All rights reserved},
  journal = {Pattern Recognition},
  keywords = {publication},
  number = {6}
}

@article{qi_convolutional_2019,
  title = {A {{Convolutional Encoder}}-{{Decoder Network}} with {{Skip Connections}} for {{Saliency Prediction}}},
  author = {Qi, Fei and Lin, Chunhuan and Shi, Guangming and Li, Hao},
  year = {2019},
  month = may,
  volume = {7},
  pages = {60428--60438},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2915630},
  abstract = {In this paper, we propose a novel convolutional encoder-decoder network with skip connections, named CEDNS, to improve the performance of saliency prediction. The encoder network utilizes the DenseNet model as the stem network to extract abundant hierarchical features from input images. Subsequently, a decoder network is designed to sufficiently fuse the hierarchical features to predict saliency more accurately. Between the encoder and decoder, skip connections are employed to transfer hierarchical features produced by the former to the latter. Furthermore, the model can be trained in an end-to-end manner which is beneficial for both training and inference. Experimental results on various benchmark datasets, SALICON, MIT300, and CAT2000, show that the proposed model achieves state-of-the-art performance on several key metrics.},
  journal = {IEEE Access},
  keywords = {NSFC,saliency}
}

@article{qi_darwinml:_2018,
  title = {{{DarwinML}}: {{A Graph}}-Based {{Evolutionary Algorithm}} for {{Automated Machine Learning}}},
  shorttitle = {{{DarwinML}}},
  author = {Qi, Fei and Xia, Zhaohui and Tang, Gaoyang and Yang, Hang and Song, Yu and Qian, Guangrui and An, Xiong and Lin, Chunhuan and Shi, Guangming},
  year = {2018},
  month = nov,
  abstract = {As an emerging field, Automated Machine Learning (AutoML) aims to reduce or eliminate manual operations that require expertise in machine learning. In this paper, a graph-based architecture is employed to represent flexible combinations of ML models, which provides a large searching space compared to tree-based and stacking-based architectures. Based on this, an evolutionary algorithm is proposed to search for the best architecture, where the mutation and heredity operators are the key for architecture evolution. With Bayesian hyper-parameter optimization, the proposed approach can automate the workflow of machine learning. On the PMLB dataset, the proposed approach shows the state-of-the-art performance compared with TPOT, Autostacker, and auto-sklearn. Some of the optimized models are with complex structures which are difficult to obtain in manual design.},
  archivePrefix = {arXiv},
  eprint = {1901.08013},
  eprinttype = {arxiv},
  journal = {arXiv:1901.08013 [cs.NE]},
  primaryClass = {cs.NE}
}

@inproceedings{qi_distorted_2004,
  title = {Distorted Grid Recognition with Its Application to Microarray Image Analysis},
  booktitle = {Third {{Int}}'l {{Conf}}. {{Image}} and {{Graphics}}},
  author = {Qi, Fei and Luo, Yupin and Hu, Dongcheng},
  year = {2004},
  month = dec,
  pages = {128--131},
  publisher = {{IEEE Computer Society}},
  address = {{Hongkong, China}},
  doi = {10.1109/ICIG.2004.57},
  keywords = {publication}
}

@incollection{qi_efficient_2002,
  title = {Efficient Automated Microarray Image Analysis},
  booktitle = {Second {{In}}'l {{Conf}}. {{Image}} and {{Graphics}}},
  author = {Qi, Fei and Hua, Chengying},
  editor = {Wei, Sui},
  year = {2002},
  month = jul,
  pages = {567--574},
  address = {{Hefei, China}},
  keywords = {publication},
  number = {4875},
  series = {Proceedings of {{SPIE}}}
}

@inproceedings{qi_extracting_2009,
  title = {Extracting Regions of Attention by Imitating the Human Visual System},
  booktitle = {{{IEEE Int}}'l {{Conf}}. {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Qi, Fei and Wu, Jinjian and Shi, Guangming},
  year = {2009},
  month = apr,
  pages = {1905--1908},
  publisher = {{IEEE Press}},
  doi = {10.1109/ICASSP.2009.4959981},
  keywords = {publication}
}

@inproceedings{qi_lda_2009,
  title = {{{LDA}} Based Color Information Fusion for Visual Objects Tracking},
  booktitle = {{{IEEE Int}}'l {{Conf}}. {{Image Processing}} ({{ICIP}})},
  author = {Qi, Fei and Song, Xiaowei and Shi, Guangming},
  year = {2009},
  month = nov,
  pages = {2201--2204},
  publisher = {{IEEE Press}},
  address = {{Cairo, Egypt}},
  doi = {10.1109/ICIP.2009.5413870},
  keywords = {publication}
}

@article{qi_recognition_2006,
  title = {Recognition of Perspectively Distorted Planar Grids},
  author = {Qi, Fei and Luo, Yupin and Hu, Dongcheng},
  year = {2006},
  month = oct,
  volume = {27},
  pages = {1725--1731},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2006.04.014},
  copyright = {All rights reserved},
  journal = {Pattern Recognition Letters},
  keywords = {publication},
  number = {14}
}

@article{qi_structure_2013,
  title = {Structure Guided Fusion for Depth Map Inpainting},
  author = {Qi, Fei and Han, Junyu and Wang, Pengjin and Shi, Guangming and Li, Fu},
  year = {2013},
  month = jan,
  volume = {34},
  pages = {70--76},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2012.06.003},
  abstract = {Depth acquisition becomes inexpensive after the revolutionary invention of Kinect. For computer vision applications, depth maps captured by Kinect require additional processing to fill up missing parts. However, conventional inpainting methods for color images cannot be applied directly to depth maps as there are not enough cues to make accurate inference about scene structures. In this paper, we propose a novel fusion based inpainting method to improve depth maps. The proposed fusion strategy integrates conventional inpainting with the recently developed non-local filtering scheme. The good balance between depth and color information guarantees an accurate inpainting result. Experimental results show the mean absolute error of the proposed method is about 20 mm, which is comparable to the precision of the Kinect sensor.},
  copyright = {All rights reserved},
  journal = {Pattern Recognition Letters},
  keywords = {publication},
  number = {1}
}

@inproceedings{qi_visual_2004,
  title = {Visual {{Tracking}} of {{Players}} through {{Occlusions}} in {{Low Resolution}}},
  booktitle = {Signal and {{Image Processing}}},
  author = {Qi, Fei and Luo, Yupin and Hu, Dongcheng},
  year = {2004},
  month = aug,
  address = {{Honolulu, Hawaii, USA}},
  keywords = {publication}
}

@article{shi_signal_2011,
  title = {Signal Matching Wavelet for Ultrasonic Flaw Detection in High Background Noise},
  author = {Shi, Guangming and Chen, Xuyang and Song, Xiaoxia and Qi, Fei and Ding, Ailing},
  year = {2011},
  month = apr,
  volume = {58},
  pages = {776--787},
  issn = {0885-3010},
  doi = {10.1109/TUFFC.2011.1870},
  copyright = {All rights reserved},
  journal = {IEEE Transanctions on Ultrasonics, Ferroelectrics and Frequency Control},
  keywords = {publication},
  number = {4}
}

@article{shi_uwb_2008,
  title = {{{UWB Echo Signal Detection With Ultra}}-{{Low Rate Sampling Based}} on {{Compressed Sensing}}},
  author = {Shi, Guangming and Lin, Jie and Chen, Xuyang and Qi, Fei and Liu, Danhua and Zhang, L.},
  year = {2008},
  month = apr,
  volume = {55},
  pages = {379--383},
  issn = {1549-7747},
  doi = {10.1109/TCSII.2008.918988},
  copyright = {All rights reserved},
  journal = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  keywords = {publication},
  number = {4}
}

@article{wang_convex_2014,
  title = {Convex {{Combination Based Target Localization}} with {{Noisy Angle}} of {{Arrival Measurements}}},
  author = {Wang, Chang and Qi, Fei and Shi, Guangming and Wang, Xiaotian},
  year = {2014},
  month = feb,
  volume = {3},
  pages = {14--17},
  doi = {10.1109/WCL.2013.101613.130587},
  abstract = {Target localization based on angle of arrival (AoA) is an important branch of location estimation research. Due to the noisy measurements from sensors and the non-linear inverse trigonometry function, the AoA-based localization induces a non-convex optimization that is difficult to solve with both high speed and accuracy simultaneously. To achieve a fast and accurate algorithm, we propose a convex combination scheme. By introducing a highly accurate linear approximation to the inverse trigonometric function, the objective is converted to a convex function, which can be solved efficiently with linear least-squares approach. The key point of the convex combination scheme is to express the coordinate of the target as the convex combination of a set of virtual anchors around its real position. Simulations demonstrate that the accuracy of this method is very close to the Cramer-Rao lower bound and that the comprehensive performance, including the accuracy and speed, is significantly improved compared to other state-of-the-art methods.},
  copyright = {All rights reserved},
  journal = {IEEE Wireless Communications Letters},
  keywords = {publication},
  number = {1}
}

@article{wang_linear_2014,
  title = {A Linear Combination-Based Weighted Least Square Approach for Target Localization with Noisy Range Measurements},
  author = {Wang, Chang and Qi, Fei and Shi, Guangming and Ren, Jingbo},
  year = {2014},
  month = jan,
  volume = {94},
  pages = {202--211},
  issn = {0165-1684},
  doi = {10.1016/j.sigpro.2013.06.005},
  abstract = {Abstract
Target localization based on range measurements from a set of anchors plays an important role in positioning systems and sensor networks. The localization is generally formulated as an optimization problem to tackle the noisy measurements. However, the objective is non-convex, and thus localization is difficult to solve in its original form. In this paper, a convex objective function is derived based on a linear combination scheme, within which the target position is expressed as a linear combination of positions of virtual anchors around its real position. In addition, the linear combination provides a highly accurate approximation for the computation of the distance from the anchors. Thus, the localization is formulated as a convex problem to find the optimal coefficients of the linear combination and is solved efficiently by the weighted linear least square method. As demonstrated by numerical experiments, the proposed approach, which achieves an approximately 35\% improvement in accuracy and 98.5\% shorter optimization time compared to the most accurate existing method, is very close to the Cram\'er\textendash Rao lower bound (CRLB) while maintaining a quite high localization speed, and also works well with real measurement data.},
  copyright = {All rights reserved},
  journal = {Signal Processing},
  keywords = {publication}
}

@inproceedings{wang_nodes_2009,
  title = {Nodes {{Placement}} for {{Optimizing Coverage}} of {{Visual Sensor Networks}}},
  booktitle = {Advances in {{Multimedia Information Processing}} ({{PCM}})},
  author = {Wang, Chang and Qi, Fei and Shi, Guang-Ming},
  editor = {Muneesawang, Paisarn and Wu, Feng and Kumazawa, Itsuo and Roeksabutr, Athikom and Liao, Mark and Tang, Xiaoou},
  year = {2009},
  pages = {1144--1149},
  publisher = {{Springer Berlin Heidelberg}},
  abstract = {Visual sensor networks have become a research focus with its expanding application domains. How to achieve optimal coverage to improve visual network's capability of obtaining regional information is a critical issue. As a visual sensor has a bounded field of view, a random deployment of network sensors can hardly solve this issue. This paper proposes a bounded observation field sensing model based on the sensing feature of visual sensor. According to this model, a sensor placement method is devised by means of multi-agent genetic algorithm (MAGA). The positions and poses of sensors which can enhance the coverage can be effectively worked out by this placement algorithm, thus the visual network's capability of obtaining regional information can be improved. Experiment results show that the algorithm proposed is effective in both 2D and 3D scenes.},
  isbn = {978-3-642-10467-1},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@inproceedings{wang_observation_2011,
  title = {Observation Quality Guaranteed Layout of Camera Networks via Sparse Representation},
  booktitle = {{{IEEE Visual Communications}} and {{Image Processing}} ({{VCIP}})},
  author = {Wang, Chang and Qi, Fei and Shi, Guangming},
  year = {2011},
  month = nov,
  publisher = {{IEEE}},
  doi = {10.1109/VCIP.2011.6116043},
  isbn = {978-1-4577-1321-7},
  keywords = {publication},
  lccn = {0000}
}

@inproceedings{wang_single-shot_2019,
  title = {A {{Single}}-{{Shot Arbitrarily}}-{{Shaped Text Detector}} Based on {{Context Attended Multi}}-{{Task Learning}}},
  booktitle = {Proceedings of the 27th {{ACM International Conference}} on {{Multimedia}} ({{MM}} '19)},
  author = {Wang, Pengfei and Zhang, Chengquan and Qi, Fei and Huang, Zuming and En, Mengyi and Han, Junyu and Liu, Jingtuo and Ding, Errui and Shi, Guangming},
  year = {2019},
  month = oct,
  publisher = {{ACM}},
  address = {{Nice, France}},
  doi = {10.1145/3343031.3350988},
  abstract = {Detecting scene text of arbitrary shapes has been a challenging task over the past years. In this paper, we propose a novel segmentation-based text detector, namely SAST, which employs a context attended multi-task learning framework based on a Fully Convolutional Network (FCN) to learn various geometric properties for the reconstruction of polygonal representation of text regions. Taking sequential characteristics of text into consideration, a Context Attention Block is introduced to capture long-range dependencies of pixel information to obtain a more reliable segmentation. In post-processing, a Point-to-Quad assignment method is proposed to cluster pixels into text instances by integrating both high-level object knowledge and low-level pixel information in a single shot. Moreover, the polygonal representation of arbitrarily-shaped text can be extracted with the proposed geometric properties much more effectively. Experiments on several benchmarks, including ICDAR2015, ICDAR2017-MLT, SCUT-CTW1500, and Total-Text, demonstrate that SAST achieves better or comparable performance in terms of accuracy. Furthermore, the proposed algorithm runs at 27.63 FPS on SCUT-CTW1500 with a Hmean of 81.0\% on a single NVIDIA Titan Xp graphics card, surpassing most of the existing segmentation-based methods.},
  archivePrefix = {arXiv},
  eprint = {1908.05498},
  eprinttype = {arxiv},
  keywords = {NSFC,saliency}
}

@article{wang_sparse_2013,
  title = {A {{Sparse Representation}}-{{Based Deployment Method}} for {{Optimizing}} the {{Observation Quality}} of {{Camera Networks}}},
  author = {Wang, Chang and Qi, Fei and Shi, Guangming and Wang, Xiaotian},
  year = {2013},
  month = aug,
  volume = {13},
  pages = {11453--11475},
  doi = {10.3390/s130911453},
  abstract = {Deployment is a critical issue affecting the quality of service of camera networks.  The deployment aims at adopting the least number of cameras to cover the whole scene,  which may have obstacles to occlude the line of sight, with expected observation quality.  This is generally formulated as a non-convex optimization problem, which is hard to solve  in polynomial time. In this paper, we propose an efficient convex solution for deployment  optimizing the observation quality based on a novel anisotropic sensing model of cameras,  which provides a reliable measurement of the observation quality. The deployment is  formulated as the selection of a subset of nodes from a redundant initial deployment with  numerous cameras, which is an {$\mathscr{l}$}0 minimization problem. Then, we relax this non-convex  optimization to a convex {$\mathscr{l}$}1 minimization employing the sparse representation. Therefore,  the high quality deployment is efficiently obtained via convex optimization. Simulation  results confirm the effectiveness of the proposed camera deployment algorithms.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  journal = {Sensors},
  keywords = {publication},
  language = {en},
  number = {9}
}

@incollection{wu_image_2012,
  title = {Image {{Quality Assessment Based}} on {{Improved Structural SIMilarity}}},
  booktitle = {Advances in {{Multimedia Information Processing}} \textemdash{} {{PCM}}},
  author = {Wu, Jinjian and Qi, Fei and Shi, Guangming},
  editor = {Lin, Weisi and Xu, Dong and Ho, Anthony and Wu, Jianxin and He, Ying and Cai, Jianfei and Kankanhalli, Mohan and Sun, Ming-Ting},
  year = {2012},
  month = jan,
  pages = {153--163},
  publisher = {{Springer B. H.}},
  isbn = {978-3-642-34777-1 978-3-642-34778-8},
  keywords = {publication},
  number = {7674},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@inproceedings{wu_improved_2010,
  title = {An Improved Model of Pixel Adaptive Just-Noticeable Difference Estimation},
  booktitle = {{{IEEE Int}}'l {{Conf}}. {{Acoustics Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Wu, Jinjian and Qi, Fei and Shi, Guangming},
  year = {2010},
  month = mar,
  pages = {2454--2457},
  publisher = {{IEEE}},
  address = {{Dallas, Texas, USA}},
  doi = {10.1109/ICASSP.2010.5496302},
  keywords = {publication}
}

@article{wu_just_2013,
  title = {Just {{Noticeable Difference Estimation}} for {{Images With Free}}-{{Energy Principle}}},
  author = {Wu, Jinjian and Shi, Guangming and Lin, Weisi and Liu, Anmin and Qi, Fei},
  year = {2013},
  month = nov,
  volume = {15},
  pages = {1705--1710},
  issn = {1520-9210},
  doi = {10.1109/TMM.2013.2268053},
  abstract = {In this paper, we introduce a novel just noticeable difference (JND) estimation model based on the unified brain theory, namely the free-energy principle. The existing pixel-based JND models mainly consider the orderly factors and always underestimate the JND threshold of the disorderly region. Recent research indicates that the human visual system (HVS) actively predicts the orderly information and avoids the residual disorderly uncertainty for image perception and understanding. Thus, we suggest that there exists disorderly concealment effect which results in high JND threshold of the disorderly region. Beginning with the Bayesian inference, we deduce an autoregressive model to imitate the active prediction of the HVS. Then, we estimate the disorderly concealment effect for the novel JND model. Experimental results confirm that the proposed JND model outperforms the relevant existing ones. Furthermore, we apply the proposed JND model in image compression, and around 15\% of bit rate can be reduced without jeopardizing the perceptual quality.},
  journal = {IEEE Transactions on Multimedia},
  number = {7}
}

@article{wu_non-local_2012,
  title = {Non-Local Spatial Redundancy Reduction for Bottom-up Saliency Estimation},
  author = {Wu, Jinjian and Qi, Fei and Shi, Guangming and Lu, Yongheng},
  year = {2012},
  month = oct,
  volume = {23},
  pages = {1158--1166},
  issn = {1047-3203},
  doi = {10.1016/j.jvcir.2012.07.010},
  copyright = {All rights reserved},
  journal = {Journal of Visual Communication and Image Representation},
  keywords = {publication},
  lccn = {0001},
  number = {7}
}

@article{wu_self-similarity_2012,
  title = {Self-Similarity Based Structural Regularity for Just Noticeable Difference Estimation},
  author = {Wu, Jinjian and Qi, Fei and Shi, Guangming},
  year = {2012},
  month = aug,
  volume = {23},
  pages = {845--852},
  issn = {1047-3203},
  doi = {10.1016/j.jvcir.2012.04.010},
  copyright = {All rights reserved},
  journal = {Journal of Visual Communication and Image Representation},
  keywords = {publication},
  lccn = {0000},
  number = {6}
}

@inproceedings{wu_unified_2011,
  title = {Unified {{Spatial Masking}} for {{Just}}-{{Noticeable Difference Estimation}}},
  booktitle = {Asia-{{Pacific Signal}} and {{Information Processing Association Annual Summit}} and {{Conference}} ({{APSIPA ASC}})},
  author = {Wu, Jinjian and Qi, Fei and Shi, Guangming},
  year = {2011},
  month = oct,
  address = {{Xi'an, China}},
  keywords = {publication}
}

@article{xia_bottom-up_2016,
  title = {Bottom-{{Up Visual Saliency Estimation}} with {{Deep Autoencoder}}-Based {{Sparse Reconstruction}}},
  author = {Xia, Chen and Qi, Fei and Shi, Guangming},
  year = {2016},
  month = jun,
  volume = {27},
  pages = {1227--1240},
  publisher = {{masterpiece}},
  doi = {10.1109/TNNLS.2015.2512898},
  abstract = {Research on visual perception indicates that the human visual system is sensitive to center-surround (C-S) contrast in the bottom-up saliency-driven attention process. Different from the traditional contrast computation of feature difference, models based on reconstruction have emerged to estimate saliency by starting from original images themselves instead of seeking for certain ad hoc features. However, in the existing reconstruction-based methods, the reconstruction parameters of each area are calculated independently without taking their global correlation into account. In this paper, inspired by the powerful feature learning and data reconstruction ability of deep autoencoders, we construct a deep C-S inference network and train it with the data sampled randomly from the entire image to obtain a unified reconstruction pattern for the current image. In this way, global competition in sampling and learning processes can be integrated into the nonlocal reconstruction and saliency estimation of each pixel, which can achieve better detection results than the models with separate consideration on local and global rarity. Moreover, by learning from the current scene, the proposed model can achieve the feature extraction and interaction simultaneously in an adaptive way, which can form a better generalization ability to handle more types of stimuli. Experimental results show that in accordance with different inputs, the network can learn distinct basic features for saliency modeling in its code layer. Furthermore, in a comprehensive evaluation on several benchmark data sets, the proposed method can outperform the existing state-of-the-art algorithms.},
  copyright = {All rights reserved},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  keywords = {NSFC,saliency},
  number = {6}
}

@inproceedings{xia_iterative_2017,
  title = {An {{Iterative Representation Learning Framework}} to {{Predict}} the {{Sequence}} of {{Eye Fixations}}},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Multimedia}} and {{Expo}} ({{ICME}})},
  author = {Xia, Chen and Qi, Fei and Shi, Guangming},
  year = {2017},
  month = jul,
  pages = {1530--1535},
  publisher = {{IEEE}},
  address = {{Hong Kong}},
  doi = {10.1109/ICME.2017.8019396},
  abstract = {Visual attention is a dynamic search process of acquiring information. However, most previous studies have focused on the prediction of static attended locations. Without considering the temporal relationship of fixations, these models usually cannot explain the dynamic saccadic behavior well. In this paper, an iterative representation learning framework is proposed to predict the saccadic scanpath. Within the proposed framework, saccade can be explained as an iterative process of finding the most uncertain area and updating the representation of scenes. In implementation, a deep autoencoder is employed for representation learning. The current fixation is predicted to be the most salient pixel, with saliency estimated by the reconstruction residual of the deep network. Image patches around this fixation are then sampled to update the network for the selection of subsequent fixations. Compared with existing models, the proposed model shows the state-of-the-art performance on several public data sets.},
  keywords = {NSFC,saliency}
}

@inproceedings{xia_nonlocal_2013,
  title = {Nonlocal Center-Surround Reconstruction-Based Bottom-up Saliency Estimation},
  booktitle = {2013 20th {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author = {Xia, Chen and Wang, Pengjin and Qi, Fei and Shi, Guangming},
  year = {2013},
  month = sep,
  pages = {206--210},
  doi = {10.1109/ICIP.2013.6738043},
  abstract = {The center-surround comparison principle is widely used in existing bottom-up saliency estimation models. However, most of them are based on local image processing techniques which are hard to handle texture regions well as a relatively large neighborhood is required to represent textures. In this paper, we propose a nonlocal patch-based reconstruction approach to reformulate the center-surround comparison. In the proposed approach, the saliency is measured by the reconstruction residual of representing the central patch with a linear combination of its surrounding patches. As a generalization of Itti et al.'s classical center-surround comparison scheme, the proposed approach performs well on images with symmetric structures where Itti et al.'s method fails, as well as on general natural images. Numerical experiments show the proposed approach produces better results compared to the state-of-the-art algorithms on several public databases.}
}

@article{xia_nonlocal_2015,
  title = {Nonlocal Center\textendash Surround Reconstruction-Based Bottom-up Saliency Estimation},
  author = {Xia, Chen and Qi, Fei and Shi, Guangming and Wang, Pengjin},
  year = {2015},
  month = apr,
  volume = {48},
  pages = {1337--1348},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2014.10.007},
  abstract = {Many saliency models consider the feature extraction as the algorithmic core and the performance of their methods relies on the selection of the features to a great extent. However, there can hardly be a set of features effective to pop out the salient regions under various visual environments. Moreover, because saliency is not tuned to certain visual features, a location winning the spatial competition in any feature space can be defined as salient. Instead of seeking for or learning the features to highlight the difference between the salient areas and the background, we focus more on the sparsity and uniqueness carried by the original image itself, the source of all the features, to propose a nonlocal reconstruction-based saliency model. In the proposed approach, the saliency is measured by the sparse reconstruction residual of representing the central patch with a linear combination of its surrounding patches sampled in a nonlocal manner. In addition, this is generalized to model the global aspect saliency, which provides a complement to the nonlocal saliency and improves the performance further. As a generalization of Itti et al.׳s classical center\textendash surround comparison scheme, the proposed approach performs well on images where Itti et al.׳s method fails, as well as on general natural images. Numerical experiments show the proposed approach produces better results compared with the state-of-the-art algorithms on three public databases.},
  copyright = {All rights reserved},
  journal = {Pattern Recognition},
  keywords = {publication},
  number = {4}
}

@article{xia_predicting_2019,
  title = {Predicting {{Human Saccadic Scanpaths Based}} on {{Iterative Representation Learning}}},
  author = {Xia, Chen and Han, Junwei and Qi, Fei and Shi, Guangming},
  year = {2019},
  month = jul,
  volume = {28},
  pages = {3502--3515},
  doi = {10.1109/TIP.2019.2897966},
  journal = {IEEE Transactions on Image Processing},
  abbr = {IEEE TIP},
  keywords = {NSFC,saliency},
  number = {7}
}

@article{xia_stereoscopic_2018,
  title = {Stereoscopic {{Saliency Estimation}} with {{Background Priors Based Deep Reconstruction}}},
  author = {Xia, Chen and Qi, Fei and Shi, Guangming and Lin, Chunhuan},
  year = {2018},
  month = dec,
  volume = {321},
  pages = {126--138},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2018.09.009},
  abstract = {Studies have implied that depth is one of the important cues guiding visual attention. However, depth information has not been well explored in existing saliency estimation models. In this paper, we propose a model inspired by the observations in three-dimensional environment to better present the influence of depth. Firstly, we use depth to estimate each region's probability of being background. Afterward, we sample pairs of surrounding and central patches from the possible background of each image to train an autoencoder-based network. As a network learned from background, it tends to describe the center-surround reconstruction pattern in background rather than foreground. Therefore, the detection of saliency can be formulated by measuring the reconstruction residual of the network. With emphasis on sampling from background, the proposed method can decrease the false positive rate in stereoscopic saliency estimation significantly. Experimental results demonstrate that the proposed method can outperform the state-of-the-art fixation prediction algorithms on several public data sets for stereoscopic saliency estimation. Additionally, it is efficiently used for proto-object extraction.},
  journal = {Neurocomputing},
  keywords = {NSFC,saliency}
}

@article{yu_stability_2018,
  title = {The Stability and Unexpected Chemistry of Oxide Clusters},
  author = {Yu, Xiaohu and Oganov, Artem R. and Zhu, Qiang and Qi, Fei and Qian, Guangrui},
  year = {2018},
  month = dec,
  volume = {20},
  pages = {30437--30444},
  issn = {1463-9084},
  doi = {10.1039/C8CP03519A},
  abstract = {Using evolutionary structure prediction and ab initio thermodynamics, we determine stable compositions and structures of small CemOn and FemOn clusters at realistic temperatures and oxygen pressures. We use second energy differences as the criterion determining clusters of particular stability (``magic'' clusters), whereas HOMO\textendash LUMO gaps are used to gauge chemical inertness \textendash{} i.e. the ability of a cluster to survive in a complex chemical environment. We find that, similar to atomic nuclei (which are clusters made of neutrons and protons), compositional space of two-component clusters also has ridges and islands of stability, surrounded by sea of instability. Long ridges of stability correspond to stoichiometric compositions \textendash{} e.g., (CeO2)k, (Ce2O3)k, (FeO)k, (Fe2O3)k and (Fe3O4)k series of clusters, while ``islands of stability'' can have very unexpected compositions. For example, at room temperature and ambient atmosphere, superoxidized Fe4O8 clusters will be dominant among the Fe4On clusters. We emphasize that stability is dictated not only by closed geometric and electronic shells, but also by magnetism.},
  journal = {Physical Chemistry Chemical Physics},
  language = {en},
  number = {48}
}


